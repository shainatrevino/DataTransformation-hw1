---
title: "Homework 1"
author: "Shaina Trevino & JP"
date: "January 24, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Creating new visualizations through joins

#### _An exploration of Kaggle's open university learning analytics dataset_

### Background

For this homework we will use data from the online data science platform [kaggle](https://www.kaggle.com/). Kaggle is an online data science platform that began as a competitive platform for predictive modeling problems. Private organizations would offer a prize, usually in the range of \$25K-$100K, for the individual or team that could provide the best predictive model for their problem. This is still a primary function of the website (see active competitions [here](https://www.kaggle.com/competitions>)), but the website has grown and is now also a place to share datasets, compete in open competitions (where you can see others code), and generally learn different facets and approaches to data science in an applied way.

#### Getting Started

You can download the data weâ€™ll use for this homework either from kaggle (requires you create an account with [kaggle](https://www.kaggle.com/rocki37/open-university-learning-analytics-dataset)) or [directly from the organization](https://analyse.kmi.open.ac.uk/open_dataset). The latter link is worth examining to learn more about the data, regardless.

A total of seven datasets (tables) related to an online learning analytics project should be included with your download. A number of keys link the various sources of data. I recommend reading through the documentation provided by the organization to better understand these keys.

```{r import_data}
library(tidyverse)
library(rio)
library(here)

student <- import(here("data", "studentInfo.csv"),
                  setclass = "tbl_df")

assessment <- import(here("data", "studentAssessment.csv"),
                          setclass = "tbl_df")

as_d <- import(here("data", "assessments.csv"),
               setclass = "tbl_df")

```

```{r keys}
student %>% count(id_student, code_presentation, code_module) %>% filter(n>1)

assessment %>% count(id_student, id_assessment) %>%  filter(n>1)

as_d %>% count(code_module, id_assessment) %>%  filter(n>1)

```

### Assignment

This primary components of this assignment are highly open-ended. These are to

1. Use at least 3 mutating joins


```{r mj3}
j_as_d <- right_join(assessment, as_d, by = "id_assessment") %>% group_by(id_student, id_assessment) %>% 
  arrange(id_student) 

key_comp <- right_join(j_as_d, student) %>% arrange(id_student)

```

```{r}
key_comp1 <- key_comp %>% group_by(id_student) %>% select(id_student, gender, highest_education, final_result)

full <- full_join(av_score, key_comp, by = "id_student")
```


1. Use at least 1 filtering join

```{r}
av_score <- key_comp %>% 
  group_by(id_student) %>% 
  summarize(av_score = mean(score)) %>% arrange(id_student)

student1 <- student %>% group_by(id_student) %>% select(id_student, gender, highest_education, final_result)

semi_join(student1, av_score) %>% arrange(id_student) #some ids are repeated beacuse people took the test twice (different years/different results)
```

1. Produce at least 3 data displays

Following the completion of these requirements, please reproduce the following figure.

```{r plot}
ggplot(full, aes(x = highest_education, y = av_score)) +
  geom_col(aes(fill = gender), position = "dodge") +
  facet_wrap(~ final_result) +
  coord_flip()
```

